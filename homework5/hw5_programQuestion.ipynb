{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KAqXcDzKwj4D"
   },
   "source": [
    "# HW5_programQuestion\n",
    "\n",
    "**Due to 11:59 pm, 18th, November 2020**\n",
    "\n",
    "**This is an individual assignment.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mqy1LtZCIQuG"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xueyiheng/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Import libraries that you might require\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import operator\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "from sklearn.metrics import accuracy_score\n",
    "import sklearn.model_selection as ms\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "U9fIU8eP_X1u"
   },
   "source": [
    "# Convolutional Neural Networks  \n",
    "In this assignment you will be training a Convolutional Neural Network on  \n",
    "the Fashion MNIST dataset.  \n",
    "\n",
    "You may find more information about the dataset [here](https://github.com/zalandoresearch/fashion-mnist).  \n",
    "For this assignment we have already loaded the dataset for you.  \n",
    "  \n",
    "You will be using PyTorch for implementing your CNN. \n",
    "\n",
    "**We highly recommend following [this tutorial](https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html#sphx-glr-beginner-blitz-cifar10-tutorial-py) for this question** as well as referring to the [official documentation](https://pytorch.org/docs/stable/nn.html) if you are unfamiliar with Pytorch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qvDAZByo_X1w"
   },
   "source": [
    "## 1. Loading the Dataset\n",
    "The output of torchvision datasets are PILImage images of range [0, 1].  \n",
    "We transform them to Tensors of normalized range [-1, 1].  \n",
    "```Transforms.Normalize((mean,),(std,))``` basically manipulates the values of a pixel such that  \n",
    "$$New\\_Value = \\frac{Old\\_Value - Mean}{Std}$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lK7aviwP_X1x"
   },
   "outputs": [],
   "source": [
    "# Define a transform to normalize the data\n",
    "\n",
    "#TODO : Set the value of mean and the standard deviation to \n",
    "#       normalize the image from range [0,1] to the range [-1, 1]\n",
    "\n",
    "\n",
    "#Begin Your Code\n",
    "\n",
    "mean = \n",
    "std = \n",
    "\n",
    "#End Your Code\n",
    "\n",
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                transforms.Normalize((mean,), (std,))\n",
    "                                ])\n",
    "\n",
    "\n",
    "#TODO : Select suitable value of batch_sizes.\n",
    "\n",
    "#Begin Your Code\n",
    "\n",
    "train_batch_size = \n",
    "test_batch_size = \n",
    "\n",
    "#End Your Code\n",
    "\n",
    "# Download and load the training data\n",
    "trainset = datasets.FashionMNIST('~/.pytorch/F_MNIST_data/', download=True, train=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=train_batch_size, shuffle=True)\n",
    "\n",
    "# Download and load the test data\n",
    "testset = datasets.FashionMNIST('~/.pytorch/F_MNIST_data/', download=True, train=False, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=test_batch_size, shuffle=True)\n",
    "\n",
    "\n",
    "# Classes\n",
    "classes = {       0 :'T-shirt/top',\n",
    "                  1 :'Trouser',\n",
    "                  2 :'Pullover',\n",
    "                  3 :'Dress',\n",
    "                  4 :'Coat',\n",
    "                  5 :'Sandal',\n",
    "                  6 :'Shirt',\n",
    "                  7 :'Sneaker',\n",
    "                  8 :'Bag',\n",
    "                  9 :'Ankle boot'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SFBh6ZhO_X1y"
   },
   "source": [
    "## 2. The Dataset\n",
    "Here we show some images of the dataset.  \n",
    "See how many of the categories can you recognise.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hX5Irrw-_X1z"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import figure\n",
    "import numpy as np\n",
    "\n",
    "# Functions to show an image\n",
    "\n",
    "\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    \n",
    "    figure(num=None, figsize=(8, 6), dpi=150, edgecolor='k')\n",
    "    plt.axis('off')\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "\n",
    "\n",
    "# get some random training images\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "# show images\n",
    "imshow(torchvision.utils.make_grid(images))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "le9N91sO_X11"
   },
   "source": [
    "## 3. Create your Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dWmqB-1b_X11"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "\n",
    "        #TODO : Design your network, you are allowed to explore your own architecture\n",
    "        #       But you should achieve a better overall accuracy than the baseline network.\n",
    "        #       Also, if you do design your own network, include an explanation \n",
    "        #       for your choice of network and how it may be better than the \n",
    "        #       baseline network.\n",
    "        \n",
    "        #Begin Your Code\n",
    "\n",
    "\n",
    "        #End Your Code\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "      #TODO : Implement the forward function that applies the layers you have created to the input\n",
    "\n",
    "      #Begin Your Code\n",
    "\n",
    "\n",
    "      #End Your Code\n",
    "\n",
    "\n",
    "net = Net()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jieF6xy__X13"
   },
   "source": [
    "## 4. Define a Loss function and optimizer\n",
    "We will be using [Cross Entropy Loss](https://pytorch.org/docs/stable/nn.html?highlight=crossentropyloss#torch.nn.CrossEntropyLoss) and [Adam optimizer](https://pytorch.org/docs/stable/optim.html?highlight=adam#torch.optim.Adam).  \n",
    "Note: PyTorch's CrossEntropyLoss combines log softmax and negative log likelihood loss in one class. Make sure you are not computing softmax twice.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_5-Qn1ef_X13"
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "#TODO : Use appropriate loss criterion and optimizer \n",
    "\n",
    "#Begin Your Code\n",
    "\n",
    "criterion = \n",
    "optimizer = \n",
    "\n",
    "#End Your Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "D4za3t0b_X15"
   },
   "source": [
    "## 5. Train the network\n",
    "\n",
    "Here we are going to train the network while logging the per batch metrics.  \n",
    "This would take some time to run (5-10 minutes).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "r7y1qZI1wyvv"
   },
   "outputs": [],
   "source": [
    "overall_step = 0\n",
    "\n",
    "#TODO : Select appropriate number of epochs\n",
    "\n",
    "#Begin Your Code\n",
    "\n",
    "epochs =\n",
    "\n",
    "#End Your Code\n",
    "\n",
    "\n",
    "for epoch in range(epochs):  # loop over the dataset multiple times\n",
    "    running_loss = 0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs\n",
    "        inputs, labels = data\n",
    "\n",
    "        #TODO : Make predictions, calculate accuracy and update your weights once\n",
    "\n",
    "        #Begin Your Code\n",
    "\n",
    "        # zero the parameter gradients\n",
    "\n",
    "        # forward + backward + optimize\n",
    "\n",
    "        #End Your Code\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 200 == 199:    # print every 200 mini-batches\n",
    "            print('Epoch: %d, Batch: %5d, loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 200))\n",
    "            running_loss = 0.0\n",
    "            #Any thing that is added to the \"info\" gets plotted in tensorboard\n",
    "            #TODO : Add the plots in Tensorboard to the report and explain what is happening\n",
    "            info = { ('loss') : loss.item(),('accuracy'): accuracy.item()}\n",
    "            for tag, value in info.items():\n",
    "                logger.scalar_summary(tag, value, overall_step+1)\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RREjngOC_X2F"
   },
   "source": [
    "## 6. Test Accuracy\n",
    "Let us look at how the network performs on the test dataset.  \n",
    "Report your accuracy in your report.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QTyWZj2R_X2F"
   },
   "outputs": [],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "#TODO : Report this accuracy in your report.\n",
    "\n",
    "print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
    "    100 * correct / total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FCCVNEjV_X2G"
   },
   "source": [
    "## 7. Per Class accuracy\n",
    "Now we see the test accuracy for each class in the test dataset.  \n",
    "Report these accuracies in your report. Also identify the problematic classes.  \n",
    "Can you explain why these classes have significantly lower accuracies compared to other classes?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CO9h7Zbd_X2H"
   },
   "outputs": [],
   "source": [
    "class_correct = list(0. for i in range(10))\n",
    "class_total = list(0. for i in range(10))\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        c = (predicted == labels).squeeze()\n",
    "        for i in range(4):\n",
    "            label = labels[i]\n",
    "            class_correct[label] += c[i].item()\n",
    "            class_total[label] += 1\n",
    "\n",
    "\n",
    "for i in range(10):\n",
    "    print('Accuracy of %5s : %2d %%' % (\n",
    "        classes[i], 100 * class_correct[i] / class_total[i]))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "hw4.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
